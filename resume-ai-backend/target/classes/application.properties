spring.application.name=resume-ai-backend

# Use DeepSeek model
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.model=deepseek-r1:1.5b

# More stable responses
spring.ai.ollama.chat.options.temperature=0.2
spring.ai.ollama.chat.options.stream=false

server.port=8080

spring.jackson.serialization.fail-on-empty-beans=false
